{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_tensorrt\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import piq\n",
    "from collections import defaultdict\n",
    "from binarization.traintools import CustomLPIPS\n",
    "\n",
    "from binarization.config import get_default_config\n",
    "from binarization.dataset import get_test_batches\n",
    "from binarization.traintools import prepare_generator, prepare_cuda_device\n",
    "from binarization.datatools import (\n",
    "    min_max_scaler,\n",
    "    inv_make_4times_downscalable,\n",
    ")\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [✅] load a model\n",
    "- [✅] fetch a pair compressed/original image\n",
    "- [✅] generated = model(compressed)\n",
    "- [✅] metric(original, generated)\n",
    "- [✅] scale up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_evaluations = 50\n",
    "default_cfg = get_default_config()\n",
    "device = prepare_cuda_device()\n",
    "lpips_alex = CustomLPIPS(net=\"alex\")\n",
    "metrics = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_cfg = default_cfg.copy()\n",
    "unet_cfg.model.name = \"unet\"\n",
    "unet_cfg.paths.ckpt_path_to_resume = Path(\n",
    "    default_cfg.paths.artifacts_dir,\n",
    "    \"best_checkpoints\",\n",
    "    \"2022_12_19_unet_4_318780.pth\",\n",
    ")\n",
    "unet = prepare_generator(unet_cfg, device).eval()\n",
    "\n",
    "test_batches = get_test_batches()\n",
    "progress_bar = tqdm(test_batches, total=n_evaluations)\n",
    "\n",
    "for step_id, (original, compressed) in enumerate(progress_bar):\n",
    "    if n_evaluations and step_id > n_evaluations - 1:\n",
    "        break\n",
    "    original = min_max_scaler(original)\n",
    "    compressed = compressed.to(device)\n",
    "\n",
    "    unet.eval()\n",
    "    with torch.no_grad():\n",
    "        generated = unet(compressed).cpu()\n",
    "    generated = inv_make_4times_downscalable(original, generated)\n",
    "\n",
    "    metrics[\"unet_lpips\"].append(lpips_alex(generated, original).item())\n",
    "    metrics[\"unet_ssim\"].append(piq.ssim(generated, original).item())\n",
    "    metrics[\"unet_psnr\"].append(piq.psnr(generated, original).item())\n",
    "    metrics['unet_ms_ssim'].append(piq.multi_scale_ssim(generated, original).item())\n",
    "    metrics['unet_brisque'].append(piq.brisque(generated).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srunet_cfg = default_cfg.copy()\n",
    "srunet_cfg.model.name = \"srunet\"\n",
    "srunet_cfg.paths.ckpt_path_to_resume = Path(\n",
    "    default_cfg.paths.artifacts_dir,\n",
    "    \"best_checkpoints\",\n",
    "    \"2022_12_19_srunet_4_318780.pth\",\n",
    ")\n",
    "srunet = prepare_generator(srunet_cfg, device).eval()\n",
    "\n",
    "test_batches = get_test_batches()\n",
    "progress_bar = tqdm(test_batches, total=n_evaluations)\n",
    "\n",
    "for step_id, (original, compressed) in enumerate(progress_bar):\n",
    "    if n_evaluations and step_id > n_evaluations - 1:\n",
    "        break\n",
    "    original = min_max_scaler(original)\n",
    "    compressed = compressed.to(device)\n",
    "\n",
    "    srunet.eval()\n",
    "    with torch.no_grad():\n",
    "        generated = srunet(compressed).cpu()\n",
    "    generated = inv_make_4times_downscalable(original, generated)\n",
    "\n",
    "    metrics[\"srunet_lpips\"].append(lpips_alex(generated, original).item())\n",
    "    metrics[\"srunet_ssim\"].append(piq.ssim(generated, original).item())\n",
    "    metrics[\"srunet_psnr\"].append(piq.psnr(generated, original).item())\n",
    "    metrics['srunet_ms_ssim'].append(piq.multi_scale_ssim(generated, original).item())\n",
    "    metrics['srunet_brisque'].append(piq.brisque(generated).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_unet = torch.jit.load(\n",
    "    default_cfg.paths.trt_dir / \"unet.ts\"\n",
    ").to(device).eval()\n",
    "\n",
    "test_batches = get_test_batches()\n",
    "progress_bar = tqdm(test_batches, total=n_evaluations)\n",
    "\n",
    "for step_id, (original, compressed) in enumerate(progress_bar):\n",
    "    if n_evaluations and step_id > n_evaluations - 1:\n",
    "        break\n",
    "    original = min_max_scaler(original)\n",
    "    compressed = compressed.to(device)\n",
    "\n",
    "    quant_unet.eval()\n",
    "    with torch.no_grad():\n",
    "        generated = quant_unet(compressed).cpu()\n",
    "    generated = inv_make_4times_downscalable(original, generated)\n",
    "\n",
    "    metrics[\"quant_unet_lpips\"].append(lpips_alex(generated, original).item())\n",
    "    metrics[\"quant_unet_ssim\"].append(piq.ssim(generated, original).item())\n",
    "    metrics[\"quant_unet_psnr\"].append(piq.psnr(generated, original).item())\n",
    "    metrics['quant_unet_ms_ssim'].append(piq.multi_scale_ssim(generated, original).item())\n",
    "    metrics['quant_unet_brisque'].append(piq.brisque(generated).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_srunet = torch.jit.load(\n",
    "    default_cfg.paths.trt_dir / \"srunet.ts\"\n",
    ").to(device).eval()\n",
    "\n",
    "test_batches = get_test_batches()\n",
    "progress_bar = tqdm(test_batches, total=n_evaluations)\n",
    "\n",
    "for step_id, (original, compressed) in enumerate(progress_bar):\n",
    "    if n_evaluations and step_id > n_evaluations - 1:\n",
    "        break\n",
    "    original = min_max_scaler(original)\n",
    "    compressed = compressed.to(device)\n",
    "\n",
    "    quant_srunet.eval()\n",
    "    with torch.no_grad():\n",
    "        generated = quant_srunet(compressed).cpu()\n",
    "    generated = inv_make_4times_downscalable(original, generated)\n",
    "\n",
    "    metrics[\"quant_srunet_lpips\"].append(lpips_alex(generated, original).item())\n",
    "    metrics[\"quant_srunet_ssim\"].append(piq.ssim(generated, original).item())\n",
    "    metrics[\"quant_srunet_psnr\"].append(piq.psnr(generated, original).item())\n",
    "    metrics['quant_srunet_ms_ssim'].append(piq.multi_scale_ssim(generated, original).item())\n",
    "    metrics['quant_srunet_brisque'].append(piq.brisque(generated).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from datetime import datetime\n",
    "\n",
    "# df = pd.DataFrame(metrics)\n",
    "# today_str = datetime.now().strftime(r\"%Y_%m_%d\")\n",
    "# save_path = default_cfg.paths.outputs_dir / f\"{today_str}_results.csv\"\n",
    "# df.to_csv(save_path, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from binarization.config import get_default_config\n",
    "\n",
    "default_cfg = get_default_config()\n",
    "results_path = default_cfg.paths.outputs_dir / \"2023_02_28_results.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(results_path)\n",
    "\n",
    "models = [\"unet\", \"srunet\", \"quant_unet\", \"quant_srunet\"]\n",
    "metrics = [\"lpips\", \"ssim\", \"psnr\", \"ms_ssim\", \"brisque\"]\n",
    "\n",
    "dfs = {}\n",
    "for metric in metrics:\n",
    "    dfs[metric] = df[[model + \"_\" + metric for model in models]]\n",
    "    dfs[metric].columns = models\n",
    "\n",
    "n_metrics = len(metrics)\n",
    "fig, ax = plt.subplots(1, n_metrics, figsize=(n_metrics * n_metrics, n_metrics), sharey=True)\n",
    "for i, k in enumerate(metrics):\n",
    "    sns.boxplot(dfs[k], ax=ax[i], orient=\"h\")\n",
    "    ax[i].set_title(k, fontsize=16)\n",
    "    ax[i].grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7f774474b43a20ce26305101b7f5844f986dc13ec8a91c410b215dc004257e9b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
