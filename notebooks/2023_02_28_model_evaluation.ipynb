{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch_tensorrt\n",
    "import piq\n",
    "from tqdm import tqdm\n",
    "\n",
    "from binarization.config import get_default_config, Gifnoc\n",
    "from binarization.dataset import get_test_batches\n",
    "from binarization.traintools import (\n",
    "    prepare_generator, prepare_cuda_device, CustomLPIPS\n",
    ")\n",
    "from binarization.datatools import (\n",
    "    min_max_scaler,\n",
    "    inv_make_4times_downscalable,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [✅] load a model\n",
    "- [✅] fetch a pair compressed/original image\n",
    "- [✅] generated = model(compressed)\n",
    "- [✅] metric(original, generated)\n",
    "- [✅] scale up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_models(\n",
    "    n_evaluations: int = 50,\n",
    ") -> dict[str, float]:\n",
    "    default_cfg = get_default_config()\n",
    "    device = prepare_cuda_device()\n",
    "\n",
    "    lpips_alex = CustomLPIPS(net=\"alex\")\n",
    "    metrics = defaultdict(list)\n",
    "    model_names = (\"unet\", \"srunet\")\n",
    "\n",
    "    for model_name in model_names:\n",
    "        cfg = default_cfg.copy()\n",
    "        cfg.model.name = model_name\n",
    "        cfg.paths.ckpt_path_to_resume = Path(\n",
    "            cfg.paths.artifacts_dir,\n",
    "            \"best_checkpoints\",\n",
    "            f\"2022_12_19_{model_name}_4_318780.pth\",\n",
    "        )\n",
    "        gen = prepare_generator(cfg, device).eval()\n",
    "\n",
    "        test_batches = get_test_batches()\n",
    "        progress_bar = tqdm(test_batches, total=n_evaluations)\n",
    "\n",
    "        for step_id, (original, compressed) in enumerate(progress_bar):\n",
    "            if n_evaluations and step_id > n_evaluations - 1:\n",
    "                break\n",
    "            original = min_max_scaler(original)\n",
    "            compressed = compressed.to(device)\n",
    "\n",
    "            gen.eval()\n",
    "            with torch.no_grad():\n",
    "                generated = gen(compressed).cpu()\n",
    "            generated = inv_make_4times_downscalable(original, generated)\n",
    "\n",
    "            metrics[f\"{model_name}_lpips\"].append(lpips_alex(generated, original).item())\n",
    "            metrics[f\"{model_name}_ssim\"].append(piq.ssim(generated, original).item())\n",
    "            metrics[f\"{model_name}_psnr\"].append(piq.psnr(generated, original).item())\n",
    "            metrics[f\"{model_name}_ms_ssim\"].append(piq.multi_scale_ssim(generated, original).item())\n",
    "            metrics[f\"{model_name}_brisque\"].append(piq.brisque(generated).item())\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_trt_models(\n",
    "    n_evaluations: int = 50,\n",
    ") -> dict[str, float]:\n",
    "    cfg = get_default_config()\n",
    "    device = prepare_cuda_device()\n",
    "    lpips_alex = CustomLPIPS(net=\"alex\")\n",
    "    metrics = defaultdict(list)\n",
    "\n",
    "    model_names = (\"unet\", \"srunet\")\n",
    "    available_dtypes = (\"fp32\", \"fp16\", \"int8\")\n",
    "\n",
    "    for model_name in model_names:\n",
    "        for dtype in available_dtypes:\n",
    "            quant_gen = torch.jit.load(\n",
    "                cfg.paths.trt_dir / f\"{model_name}_{dtype}.ts\"\n",
    "            ).to(device).eval()\n",
    "\n",
    "            test_batches = get_test_batches()\n",
    "            progress_bar = tqdm(test_batches, total=n_evaluations)\n",
    "\n",
    "            for step_id, (original, compressed) in enumerate(progress_bar):\n",
    "                if n_evaluations and step_id > n_evaluations - 1:\n",
    "                    break\n",
    "                original = min_max_scaler(original)\n",
    "                compressed = compressed.to(device)\n",
    "\n",
    "                if dtype == \"fp16\":\n",
    "                    compressed = compressed.half()\n",
    "                elif dtype not in {\"fp32\", \"int8\"}:\n",
    "                    raise ValueError(\n",
    "                        f\"Unknown dtype: {dtype}. Choose in {'fp32', 'fp16', 'int8'}.\"\n",
    "                    )\n",
    "\n",
    "                quant_gen.eval()\n",
    "                with torch.no_grad():\n",
    "                    generated = quant_gen(compressed).cpu()\n",
    "                generated = inv_make_4times_downscalable(original, generated)\n",
    "\n",
    "                metrics[f\"{model_name}_{dtype}_lpips\"].append(lpips_alex(generated, original).item())\n",
    "                metrics[f\"{model_name}_{dtype}_ssim\"].append(piq.ssim(generated, original).item())\n",
    "                metrics[f\"{model_name}_{dtype}_psnr\"].append(piq.psnr(generated, original).item())\n",
    "                metrics[f\"{model_name}_{dtype}_ms_ssim\"].append(piq.multi_scale_ssim(generated, original).item())\n",
    "                metrics[f\"{model_name}_{dtype}_brisque\"].append(piq.brisque(generated).item())\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "def save_json(json_obj: dict, save_path: Path):\n",
    "    with open(save_path, \"w\") as out_file:\n",
    "        json.dump(json_obj, out_file)\n",
    "\n",
    "n_evaluations = 30\n",
    "metrics = eval_models(n_evaluations=n_evaluations)\n",
    "trt_metrics = eval_trt_models(n_evaluations=n_evaluations)\n",
    "\n",
    "metrics.update(trt_metrics)\n",
    "today_str = datetime.now().strftime(r\"%Y_%m_%d\")\n",
    "cfg = get_default_config()\n",
    "save_path = cfg.paths.outputs_dir / f\"{today_str}_metrics.json\"\n",
    "save_json(metrics, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from datetime import datetime\n",
    "\n",
    "# df = pd.DataFrame(metrics)\n",
    "# today_str = datetime.now().strftime(r\"%Y_%m_%d\")\n",
    "# save_path = default_cfg.paths.outputs_dir / f\"{today_str}_results.csv\"\n",
    "# df.to_csv(save_path, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from datetime import datetime\n",
    "today_str = datetime.now().strftime(r\"%Y_%m_%d\")\n",
    "cfg = get_default_config()\n",
    "metrics_json_path = cfg.paths.outputs_dir / f\"{today_str}_metrics.json\"\n",
    "with open(metrics_json_path, \"r\") as in_file:\n",
    "    metrics_json = json.load(in_file)\n",
    "\n",
    "df = pd.DataFrame(metrics_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = [\n",
    "    [\n",
    "        \"unet\",\n",
    "        \"unet_fp32\",\n",
    "        \"unet_fp16\",\n",
    "        \"unet_int8\",\n",
    "        \"srunet\",\n",
    "        \"srunet_fp32\",\n",
    "        \"srunet_fp16\",\n",
    "        \"srunet_int8\"\n",
    "    ],\n",
    "    [\n",
    "        \"unet_fp32\",\n",
    "        \"unet_fp16\",\n",
    "        \"unet_int8\",\n",
    "    ],\n",
    "    [\n",
    "        \"srunet_fp32\",\n",
    "        \"srunet_fp16\",\n",
    "        \"srunet_int8\"\n",
    "    ],\n",
    "]\n",
    "metrics = [\"lpips\", \"ssim\", \"psnr\", \"ms_ssim\", \"brisque\"]\n",
    "\n",
    "for models in models_list:\n",
    "    dfs = {}\n",
    "    for metric in metrics:\n",
    "        dfs[metric] = df[[model + \"_\" + metric for model in models]]\n",
    "        dfs[metric].columns = models\n",
    "        n_metrics = len(metrics)\n",
    "    # fig, ax = plt.subplots(1, n_metrics, figsize=(n_metrics * n_metrics, n_metrics), sharey=True)\n",
    "    fig, ax = plt.subplots(1, n_metrics, figsize=(20, 3), sharey=True)\n",
    "    for i, k in enumerate(metrics):\n",
    "        # sns.boxplot(dfs[k].apply(lambda x: x.round(2), axis=0), ax=ax[i], orient=\"h\")\n",
    "        sns.boxplot(dfs[k], ax=ax[i], orient=\"h\")\n",
    "        ax[i].set_title(k, fontsize=16)\n",
    "        ax[i].grid() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "cfg = get_default_config()\n",
    "today_str = datetime.now().strftime(r\"%Y_%m_%d\")\n",
    "unet_timings_json_path = cfg.paths.outputs_dir / f\"{today_str}_timings_unet.json\"\n",
    "srunet_timings_json_path = cfg.paths.outputs_dir / f\"{today_str}_timings_srunet.json\"\n",
    "\n",
    "with open(unet_timings_json_path, \"r\") as in_file:\n",
    "    unet_timings_dict = json.load(in_file)\n",
    "with open(srunet_timings_json_path, \"r\") as in_file:\n",
    "    srunet_timings_dict = json.load(in_file)\n",
    "unet_timings_dict.update(srunet_timings_dict)\n",
    "timings = pd.DataFrame(unet_timings_dict)\n",
    "save_path = cfg.paths.outputs_dir / f\"{today_str}_timings.csv\"\n",
    "timings.to_csv(save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timings /= 1e+9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = [\n",
    "    [\n",
    "        \"unet\",\n",
    "        \"unet_fp32\",\n",
    "        \"unet_fp16\",\n",
    "        \"unet_int8\",\n",
    "        \"srunet\",\n",
    "        \"srunet_fp32\",\n",
    "        \"srunet_fp16\",\n",
    "        \"srunet_int8\"\n",
    "    ],\n",
    "    [\n",
    "        \"unet_fp32\",\n",
    "        \"unet_fp16\",\n",
    "        \"unet_int8\",\n",
    "    ],\n",
    "    [\n",
    "        \"srunet_fp32\",\n",
    "        \"srunet_fp16\",\n",
    "        \"srunet_int8\"\n",
    "    ],\n",
    "]\n",
    "fig, ax = plt.subplots(len(models_list), 1, figsize=(12, 8), sharex=True)\n",
    "for i, k in enumerate(models_list):\n",
    "    # sns.boxplot(dfs[k].apply(lambda x: x.round(2), axis=0), ax=ax[i], orient=\"h\")\n",
    "    sns.boxplot(timings[k], ax=ax[i], orient=\"h\")\n",
    "    # ax[i].set_title(k, fontsize=16)\n",
    "    ax[i].grid()\n",
    "ax[len(models_list) - 1].set_xlabel(\"seconds\")\n",
    "fig.suptitle(\"Time elapsed evaluating one image in seconds\")\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7f774474b43a20ce26305101b7f5844f986dc13ec8a91c410b215dc004257e9b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
